\section{Methodology}

\subsection{System Architecture}
The pipeline consists of three stages: (1) Hand Landmark Extraction, (2) Feature Engineering, and (3) Hybrid Recognition Logic.

\subsection{Feature Extraction}
We utilize MediaPipe Hands to detect 21 3D landmarks per hand. The raw $x, y, z$ coordinates are flattened into a 63-dimensional feature vector.
\begin{equation}
   F = [x_0, y_0, z_0, \dots, x_{20}, y_{20}, z_{20}]
\end{equation}
These features are normalized using a standard scaler to zero mean and unit variance before classification.

\subsection{Static Gesture Classification}
A Support Vector Machine (SVM) with a Radial Basis Function (RBF) kernel is employed for pose classification. The model is trained on a custom dataset of four classes:
\begin{itemize}
   \item \textbf{Stop:} Play/Pause
   \item \textbf{Fist:} Mute Toggle
   \item \textbf{Like:} Volume Up
   \item \textbf{Thumbs Down:} Volume Down
\end{itemize}
We apply a confidence threshold ($\tau = 0.88$) and a temporal stability check (3 consecutive frames) to filter noise and prevent jitter.

\subsection{Zone-Based Navigation}
To enable robust track navigation (Next/Previous) without the fragility of velocity thresholds, we partition the frame into three vertical zones: Left ($x < 0.25$), Center, and Right ($x > 0.75$). A finite state machine triggers actions only when the wrist landmark transitions from the Center zone to an edge zone, enforced by a 1.5-second cooldown.