{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Static Hand Gesture UI Control\n",
    "\n",
    "**Course Project:** Computer Vision Applications  \n",
    "**Goal:** Control PC volume and media playback using real-time static hand gestures.\n",
    "\n",
    "**Demo:** [Watch the gesture walkthrough](https://www.youtube.com/watch?v=pzKSvmTijoU) before running the notebook to see the expected interactions.\n",
    "\n",
    "## Project Overview\n",
    "This project implements a touchless interface using a standard webcam. It detects hand landmarks using **MediaPipe Hands**, extracts a 63-dimensional feature vector (21 points × x,y,z), and classifies the pose using a **Support Vector Machine (SVM)**. The recognized gestures are then mapped to system actions (Volume Up/Down, Mute, Play/Pause) via Python automation libraries.\n",
    "\n",
    "### Workflow\n",
    "1.  **Data Collection:** Capture labeled landmark samples for 5 gestures (Stop, Fist, Victory, Like, OK).\n",
    "2.  **Model Training:** Train a lightweight SVM classifier on the collected dataset.\n",
    "3.  **Real-Time Demo:** Run a live inference loop to control the PC.\n",
    "\n",
    "## Setup Instructions\n",
    "1.  **Create Environment:**\n",
    "    ```powershell\n",
    "    python -m venv .venv\n",
    "    .\\.venv\\Scripts\\Activate.ps1\n",
    "    ```\n",
    "2.  **Install Dependencies:**\n",
    "    ```powershell\n",
    "    pip install -r requirements.txt\n",
    "    ```\n",
    "3.  **Run Notebook:** Execute the cells below in order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo Recording\n",
    "A short walkthrough of the zone-based controller is available here: [Gesture Control Demo](https://www.youtube.com/watch?v=pzKSvmTijoU).\n",
    "\n",
    "> Preview thumbnail (click to open):\n",
    "[![Gesture demo thumbnail](https://img.youtube.com/vi/pzKSvmTijoU/0.jpg)](https://www.youtube.com/watch?v=pzKSvmTijoU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Madi\\Documents\\season_25-26\\academic_25-26\\EE4211\\compvision_proj\\gesture-recog\\.venv\\Scripts\\python.exe\n",
      "3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection\n",
    "\n",
    "This module captures landmark coordinate samples for training the SVM classifier. The system records 63-dimensional feature vectors (21 MediaPipe hand landmarks × x,y,z coordinates) for four static gesture classes:\n",
    "\n",
    "| Class | Gesture | Description |\n",
    "|-------|---------|-------------|\n",
    "| 0 | Stop | Open palm, all fingers extended |\n",
    "| 1 | Fist | Closed hand |\n",
    "| 2 | Like | Thumbs up |\n",
    "| 3 | Thumbs Down | Thumb pointing downward |\n",
    "\n",
    "**Navigation gestures** (Next/Previous track) are implemented via zone-based detection and do not require training data.\n",
    "\n",
    "### Data Collection Protocol\n",
    "\n",
    "**Note:** A pre-collected `gesture_data.csv` file is included in the repository for demonstration purposes. You can proceed directly to the training phase using this dataset. If you wish to collect fresh samples or customize the gestures, simply delete the existing CSV file and execute the cell below to record new data.\n",
    "\n",
    "1. **Environment Setup:**\n",
    "   - Activate virtual environment: `.\\.venv\\Scripts\\Activate.ps1`\n",
    "   - Verify dependencies installed: `pip list`\n",
    "   - Ensure adequate lighting and camera functionality\n",
    "\n",
    "2. **Recording Procedure:**\n",
    "   - Execute the cell below to launch the collection interface\n",
    "   - Press numeric keys `0`–`3` to begin recording each gesture class\n",
    "   - Hold each pose for 3–5 seconds while moving slightly to capture variance\n",
    "   - Press `SPACE` to pause between gesture transitions\n",
    "   - Target: **≥200 samples per class** (800 total minimum)\n",
    "\n",
    "3. **Data Augmentation:**\n",
    "   - Vary hand distance from camera (0.5m – 1.5m)\n",
    "   - Include slight rotations (±15°)\n",
    "   - Capture under different lighting conditions\n",
    "   - Use both left and right hands\n",
    "\n",
    "4. **Output:**\n",
    "   - Press `q` to terminate and save\n",
    "   - Dataset saved to `gesture_data.csv` in project root\n",
    "   - Console displays per-class sample counts and validation status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATA COLLECTION STARTED (Dual Hand Support)\n",
      "============================================================\n",
      "Instructions:\n",
      "  - Press 0-3 to start recording that gesture\n",
      "  - Press SPACE to PAUSE recording (use this to switch gestures!)\n",
      "  - Hold the pose for a few seconds (aim for ~200+ samples per gesture)\n",
      "  - You can use ONE or BOTH hands. Each detected hand counts as a sample.\n",
      "  - Press 'q' in the video window to quit and save\n",
      "============================================================\n",
      "\n",
      "Waiting for gesture selection...\n",
      "\n",
      ">>> Now recording: Stop\n",
      "\n",
      ">>> Now recording: Stop\n",
      "\n",
      "Progress: 51 total samples collected\n",
      "  0: Stop = 49 samples\n",
      "  1: Fist = 0 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 51 total samples collected\n",
      "  0: Stop = 49 samples\n",
      "  1: Fist = 0 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 101 total samples collected\n",
      "  0: Stop = 99 samples\n",
      "  1: Fist = 0 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 101 total samples collected\n",
      "  0: Stop = 99 samples\n",
      "  1: Fist = 0 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 151 total samples collected\n",
      "  0: Stop = 149 samples\n",
      "  1: Fist = 0 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 151 total samples collected\n",
      "  0: Stop = 149 samples\n",
      "  1: Fist = 0 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 201 total samples collected\n",
      "  0: Stop = 199 samples\n",
      "  1: Fist = 0 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 201 total samples collected\n",
      "  0: Stop = 199 samples\n",
      "  1: Fist = 0 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 251 total samples collected\n",
      "  0: Stop = 249 samples\n",
      "  1: Fist = 0 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 251 total samples collected\n",
      "  0: Stop = 249 samples\n",
      "  1: Fist = 0 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 301 total samples collected\n",
      "  0: Stop = 300 samples\n",
      "  1: Fist = 0 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 301 total samples collected\n",
      "  0: Stop = 300 samples\n",
      "  1: Fist = 0 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 352 total samples collected\n",
      "  0: Stop = 350 samples\n",
      "  1: Fist = 0 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 352 total samples collected\n",
      "  0: Stop = 350 samples\n",
      "  1: Fist = 0 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 402 total samples collected\n",
      "  0: Stop = 400 samples\n",
      "  1: Fist = 0 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 402 total samples collected\n",
      "  0: Stop = 400 samples\n",
      "  1: Fist = 0 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 452 total samples collected\n",
      "  0: Stop = 450 samples\n",
      "  1: Fist = 0 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 452 total samples collected\n",
      "  0: Stop = 450 samples\n",
      "  1: Fist = 0 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 502 total samples collected\n",
      "  0: Stop = 500 samples\n",
      "  1: Fist = 0 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 502 total samples collected\n",
      "  0: Stop = 500 samples\n",
      "  1: Fist = 0 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 552 total samples collected\n",
      "  0: Stop = 550 samples\n",
      "  1: Fist = 0 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 552 total samples collected\n",
      "  0: Stop = 550 samples\n",
      "  1: Fist = 0 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 602 total samples collected\n",
      "  0: Stop = 600 samples\n",
      "  1: Fist = 0 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 602 total samples collected\n",
      "  0: Stop = 600 samples\n",
      "  1: Fist = 0 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 652 total samples collected\n",
      "  0: Stop = 650 samples\n",
      "  1: Fist = 0 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 652 total samples collected\n",
      "  0: Stop = 650 samples\n",
      "  1: Fist = 0 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 702 total samples collected\n",
      "  0: Stop = 700 samples\n",
      "  1: Fist = 0 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 702 total samples collected\n",
      "  0: Stop = 700 samples\n",
      "  1: Fist = 0 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 752 total samples collected\n",
      "  0: Stop = 750 samples\n",
      "  1: Fist = 0 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 752 total samples collected\n",
      "  0: Stop = 750 samples\n",
      "  1: Fist = 0 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 802 total samples collected\n",
      "  0: Stop = 800 samples\n",
      "  1: Fist = 0 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 802 total samples collected\n",
      "  0: Stop = 800 samples\n",
      "  1: Fist = 0 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 852 total samples collected\n",
      "  0: Stop = 850 samples\n",
      "  1: Fist = 0 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 852 total samples collected\n",
      "  0: Stop = 850 samples\n",
      "  1: Fist = 0 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 902 total samples collected\n",
      "  0: Stop = 900 samples\n",
      "  1: Fist = 0 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 902 total samples collected\n",
      "  0: Stop = 900 samples\n",
      "  1: Fist = 0 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      ">>> PAUSED recording. Switch your hand pose, then press 0-3 to resume.\n",
      "\n",
      ">>> PAUSED recording. Switch your hand pose, then press 0-3 to resume.\n",
      "\n",
      ">>> Now recording: Fist\n",
      "\n",
      ">>> Now recording: Fist\n",
      "\n",
      "Progress: 952 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 4 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 952 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 4 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 1002 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 53 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 1002 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 53 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 1052 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 103 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 1052 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 103 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 1102 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 153 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 1102 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 153 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 1152 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 203 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 1152 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 203 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 1202 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 253 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 1202 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 253 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 1252 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 303 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 1252 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 303 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 1302 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 353 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 1302 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 353 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 1352 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 403 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 1352 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 403 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 1402 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 453 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 1402 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 453 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 1452 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 503 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 1452 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 503 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 1502 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 553 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 1502 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 553 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 1552 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 603 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 1552 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 603 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 1602 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 653 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 1602 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 653 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 1652 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 703 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 1652 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 703 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 1702 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 753 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 1702 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 753 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 1752 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 803 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 1752 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 803 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 1802 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 853 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 1802 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 853 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 1852 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 903 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 1852 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 903 samples\n",
      "  2: Like = 0 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      ">>> PAUSED recording. Switch your hand pose, then press 0-3 to resume.\n",
      "\n",
      ">>> PAUSED recording. Switch your hand pose, then press 0-3 to resume.\n",
      "\n",
      ">>> Now recording: Like\n",
      "\n",
      ">>> Now recording: Like\n",
      "\n",
      "Progress: 1902 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 16 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 1902 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 16 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 1952 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 65 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 1952 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 65 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 2002 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 115 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 2002 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 115 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 2052 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 165 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 2052 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 165 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 2102 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 215 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 2102 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 215 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 2152 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 265 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 2152 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 265 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 2202 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 315 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 2202 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 315 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 2252 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 365 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 2252 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 365 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 2302 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 415 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 2302 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 415 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 2352 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 465 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 2352 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 465 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 2402 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 515 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 2402 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 515 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 2452 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 565 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 2452 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 565 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 2502 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 615 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 2502 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 615 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 2552 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 665 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 2552 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 665 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 2602 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 715 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 2602 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 715 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 2652 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 765 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 2652 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 765 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 2702 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 815 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 2702 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 815 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 2752 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 865 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 2752 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 865 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 2802 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 916 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      "Progress: 2802 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 916 samples\n",
      "  3: Thumbs Down = 0 samples\n",
      "\n",
      ">>> PAUSED recording. Switch your hand pose, then press 0-3 to resume.\n",
      "\n",
      ">>> PAUSED recording. Switch your hand pose, then press 0-3 to resume.\n",
      "\n",
      ">>> Now recording: Thumbs Down\n",
      "\n",
      ">>> Now recording: Thumbs Down\n",
      "\n",
      "Progress: 2852 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 948 samples\n",
      "  3: Thumbs Down = 17 samples\n",
      "\n",
      "Progress: 2852 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 948 samples\n",
      "  3: Thumbs Down = 17 samples\n",
      "\n",
      "Progress: 2902 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 948 samples\n",
      "  3: Thumbs Down = 67 samples\n",
      "\n",
      "Progress: 2902 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 948 samples\n",
      "  3: Thumbs Down = 67 samples\n",
      "\n",
      "Progress: 2952 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 948 samples\n",
      "  3: Thumbs Down = 117 samples\n",
      "\n",
      "Progress: 2952 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 948 samples\n",
      "  3: Thumbs Down = 117 samples\n",
      "\n",
      "Progress: 3002 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 948 samples\n",
      "  3: Thumbs Down = 167 samples\n",
      "\n",
      "Progress: 3002 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 948 samples\n",
      "  3: Thumbs Down = 167 samples\n",
      "\n",
      "Progress: 3052 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 948 samples\n",
      "  3: Thumbs Down = 217 samples\n",
      "\n",
      "Progress: 3052 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 948 samples\n",
      "  3: Thumbs Down = 217 samples\n",
      "\n",
      "Progress: 3102 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 948 samples\n",
      "  3: Thumbs Down = 267 samples\n",
      "\n",
      "Progress: 3102 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 948 samples\n",
      "  3: Thumbs Down = 267 samples\n",
      "\n",
      "Progress: 3152 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 948 samples\n",
      "  3: Thumbs Down = 317 samples\n",
      "\n",
      "Progress: 3152 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 948 samples\n",
      "  3: Thumbs Down = 317 samples\n",
      "\n",
      "Progress: 3202 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 948 samples\n",
      "  3: Thumbs Down = 367 samples\n",
      "\n",
      "Progress: 3202 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 948 samples\n",
      "  3: Thumbs Down = 367 samples\n",
      "\n",
      "Progress: 3252 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 948 samples\n",
      "  3: Thumbs Down = 417 samples\n",
      "\n",
      "Progress: 3252 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 948 samples\n",
      "  3: Thumbs Down = 417 samples\n",
      "\n",
      "Progress: 3302 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 948 samples\n",
      "  3: Thumbs Down = 467 samples\n",
      "\n",
      "Progress: 3302 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 948 samples\n",
      "  3: Thumbs Down = 467 samples\n",
      "\n",
      "Progress: 3352 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 948 samples\n",
      "  3: Thumbs Down = 517 samples\n",
      "\n",
      "Progress: 3352 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 948 samples\n",
      "  3: Thumbs Down = 517 samples\n",
      "\n",
      "Progress: 3402 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 948 samples\n",
      "  3: Thumbs Down = 567 samples\n",
      "\n",
      "Progress: 3402 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 948 samples\n",
      "  3: Thumbs Down = 567 samples\n",
      "\n",
      "Progress: 3452 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 948 samples\n",
      "  3: Thumbs Down = 617 samples\n",
      "\n",
      "Progress: 3452 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 948 samples\n",
      "  3: Thumbs Down = 617 samples\n",
      "\n",
      "Progress: 3502 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 948 samples\n",
      "  3: Thumbs Down = 667 samples\n",
      "\n",
      "Progress: 3502 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 948 samples\n",
      "  3: Thumbs Down = 667 samples\n",
      "\n",
      "Progress: 3552 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 948 samples\n",
      "  3: Thumbs Down = 717 samples\n",
      "\n",
      "Progress: 3552 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 948 samples\n",
      "  3: Thumbs Down = 717 samples\n",
      "\n",
      "Progress: 3602 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 948 samples\n",
      "  3: Thumbs Down = 767 samples\n",
      "\n",
      "Progress: 3602 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 948 samples\n",
      "  3: Thumbs Down = 767 samples\n",
      "\n",
      "Progress: 3652 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 948 samples\n",
      "  3: Thumbs Down = 817 samples\n",
      "\n",
      "Progress: 3652 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 948 samples\n",
      "  3: Thumbs Down = 817 samples\n",
      "\n",
      "Progress: 3702 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 948 samples\n",
      "  3: Thumbs Down = 867 samples\n",
      "\n",
      "Progress: 3702 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 948 samples\n",
      "  3: Thumbs Down = 867 samples\n",
      "\n",
      "Progress: 3752 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 948 samples\n",
      "  3: Thumbs Down = 918 samples\n",
      "\n",
      "Progress: 3752 total samples collected\n",
      "  0: Stop = 947 samples\n",
      "  1: Fist = 938 samples\n",
      "  2: Like = 948 samples\n",
      "  3: Thumbs Down = 918 samples\n",
      "\n",
      ">>> PAUSED recording. Switch your hand pose, then press 0-3 to resume.\n",
      "\n",
      ">>> PAUSED recording. Switch your hand pose, then press 0-3 to resume.\n",
      "\n",
      "Quitting...\n",
      "\n",
      "Quitting...\n",
      "\n",
      "============================================================\n",
      "SUCCESS! Saved 3778 samples to gesture_data.csv\n",
      "============================================================\n",
      "Sample breakdown:\n",
      "  ✓ 0: Stop = 947 samples\n",
      "  ✓ 1: Fist = 938 samples\n",
      "  ✓ 2: Like = 948 samples\n",
      "  ✓ 3: Thumbs Down = 945 samples\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "SUCCESS! Saved 3778 samples to gesture_data.csv\n",
      "============================================================\n",
      "Sample breakdown:\n",
      "  ✓ 0: Stop = 947 samples\n",
      "  ✓ 1: Fist = 938 samples\n",
      "  ✓ 2: Like = 948 samples\n",
      "  ✓ 3: Thumbs Down = 945 samples\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import csv\n",
    "from collections import Counter\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "# Updated to support 2 hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.7)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Updated gesture list: Removed Victory/Rock, kept others\n",
    "gesture_names = [\"Stop\", \"Fist\", \"Like\", \"Thumbs Down\"]\n",
    "data = []\n",
    "sample_counts = Counter()  # Track samples per gesture\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "current_gesture = -1\n",
    "\n",
    "# Make window visible and position it\n",
    "window_name = 'Data Collection – Press 0–3 to record, q to quit'\n",
    "cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(window_name, 800, 600)\n",
    "cv2.moveWindow(window_name, 100, 100)  # Position at top-left\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATA COLLECTION STARTED (Dual Hand Support)\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Instructions:\")\n",
    "print(\"  - Press 0-3 to start recording that gesture\")\n",
    "print(\"  - Press SPACE to PAUSE recording (use this to switch gestures!)\")\n",
    "print(\"  - Hold the pose for a few seconds (aim for ~200+ samples per gesture)\")\n",
    "print(\"  - You can use ONE or BOTH hands. Each detected hand counts as a sample.\")\n",
    "print(\"  - Press 'q' in the video window to quit and save\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nWaiting for gesture selection...\")\n",
    "\n",
    "frame_count = 0\n",
    "last_print_count = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"ERROR: Could not read from camera. Check camera permissions.\")\n",
    "        break\n",
    "    \n",
    "    frame = cv2.flip(frame, 1)  # mirror\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(rgb_frame)\n",
    "\n",
    "    # Count samples per gesture for display\n",
    "    if data:\n",
    "        sample_counts = Counter([row[-1] for row in data])\n",
    "    \n",
    "    # Draw on frame\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            # Extract & save when recording\n",
    "            if 0 <= current_gesture < len(gesture_names):\n",
    "                landmarks = []\n",
    "                for lm in hand_landmarks.landmark:\n",
    "                    landmarks.extend([lm.x, lm.y, lm.z])\n",
    "                landmarks.append(current_gesture)  # label at the end\n",
    "                data.append(landmarks)\n",
    "        \n",
    "        # Show current gesture name and sample count\n",
    "        if 0 <= current_gesture < len(gesture_names):\n",
    "            count = sample_counts.get(current_gesture, 0)\n",
    "            text = f\"Recording: {gesture_names[current_gesture]} ({count} samples)\"\n",
    "            cv2.putText(frame, text, (10, 60),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 3)\n",
    "        else:\n",
    "            cv2.putText(frame, \"PAUSED: Press 0-3 to record\", (10, 60),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
    "    else:\n",
    "        # No hand detected\n",
    "        if current_gesture >= 0:\n",
    "            cv2.putText(frame, f\"Recording: {gesture_names[current_gesture]} (no hand detected)\", \n",
    "                       (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "    \n",
    "    # Show sample counts for all gestures\n",
    "    y_offset = 100\n",
    "    cv2.putText(frame, \"Sample counts:\", (10, y_offset),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "    for i, name in enumerate(gesture_names):\n",
    "        count = sample_counts.get(i, 0)\n",
    "        color = (0, 255, 0) if count >= 200 else (0, 165, 255) if count >= 100 else (0, 0, 255)\n",
    "        cv2.putText(frame, f\"  {i}: {name} = {count}\", (10, y_offset + 30 + i * 25),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "    \n",
    "    # Show total\n",
    "    total = len(data)\n",
    "    cv2.putText(frame, f\"TOTAL: {total} samples\", (10, y_offset + 180),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(window_name, frame)\n",
    "\n",
    "    # Print progress every 50 samples\n",
    "    if len(data) - last_print_count >= 50:\n",
    "        print(f\"\\nProgress: {len(data)} total samples collected\")\n",
    "        for i, name in enumerate(gesture_names):\n",
    "            count = sample_counts.get(i, 0)\n",
    "            print(f\"  {i}: {name} = {count} samples\")\n",
    "        last_print_count = len(data)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        print(\"\\nQuitting...\")\n",
    "        break\n",
    "    elif key == ord(' '):\n",
    "        current_gesture = -1\n",
    "        print(\"\\n>>> PAUSED recording. Switch your hand pose, then press 0-3 to resume.\")\n",
    "    elif key in [ord('0'), ord('1'), ord('2'), ord('3')]:\n",
    "        current_gesture = int(chr(key))\n",
    "        print(f\"\\n>>> Now recording: {gesture_names[current_gesture]}\")\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Save\n",
    "if data:\n",
    "    with open('gesture_data.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([f'x{i}' for i in range(63)] + ['label'])\n",
    "        writer.writerows(data)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"SUCCESS! Saved {len(data)} samples to gesture_data.csv\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Sample breakdown:\")\n",
    "    final_counts = Counter([row[-1] for row in data])\n",
    "    for i, name in enumerate(gesture_names):\n",
    "        count = final_counts.get(i, 0)\n",
    "        status = \"✓\" if count >= 200 else \"⚠\" if count >= 100 else \"✗\"\n",
    "        print(f\"  {status} {i}: {name} = {count} samples\")\n",
    "    print(\"=\" * 60)\n",
    "else:\n",
    "    print(\"\\nWARNING: No data collected! Make sure to press 0-3 to start recording.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training & Evaluation\n",
    "\n",
    "This module trains a Support Vector Machine (SVM) classifier on the collected landmark dataset and evaluates its performance using standard machine learning metrics.\n",
    "\n",
    "### Pipeline Architecture\n",
    "\n",
    "**Preprocessing:**\n",
    "- `StandardScaler`: Normalizes feature vectors to zero mean and unit variance\n",
    "- Applied to all 63 dimensions (21 landmarks × 3 coordinates)\n",
    "\n",
    "**Classifier Configuration:**\n",
    "- **Algorithm:** Support Vector Machine (SVM)\n",
    "- **Kernel:** Radial Basis Function (RBF)\n",
    "- **Regularization:** C=10\n",
    "- **Gamma:** Auto-scaled based on feature variance\n",
    "- **Probability Estimates:** Enabled for confidence scoring\n",
    "\n",
    "### Training Procedure\n",
    "\n",
    "1. Load `gesture_data.csv` from project root\n",
    "2. Split dataset: 80% training, 20% testing (stratified by class)\n",
    "3. Fit preprocessing + SVM pipeline on training set\n",
    "4. Generate performance metrics on test set\n",
    "5. Serialize trained model to `gesture_classifier.pkl`\n",
    "\n",
    "### Evaluation Metrics\n",
    "\n",
    "- **Overall Accuracy:** Classification rate on test set\n",
    "- **Per-Class Precision/Recall/F1:** Breakdown by gesture\n",
    "- **Confusion Matrix:** Heatmap visualization of prediction patterns\n",
    "\n",
    "**Prerequisites:** Ensure `gesture_data.csv` exists in project root with ≥800 samples before executing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 1.0000\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Stop', 'Fist', 'Like', 'Thumbs Down'], dtype='object')] are in the [index]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 46\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Build per-class metrics table\u001b[39;00m\n\u001b[0;32m     38\u001b[0m report_dict \u001b[38;5;241m=\u001b[39m classification_report(\n\u001b[0;32m     39\u001b[0m     y_test,\n\u001b[0;32m     40\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     43\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m     44\u001b[0m )\n\u001b[0;32m     45\u001b[0m per_class_df \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m---> 46\u001b[0m     \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreport_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgesture_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprecision\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrecall\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mf1-score\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msupport\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGesture\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1-score\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[0;32m     50\u001b[0m )\n\u001b[0;32m     51\u001b[0m per_class_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupport\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m per_class_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupport\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m     52\u001b[0m styled_metrics \u001b[38;5;241m=\u001b[39m per_class_df\u001b[38;5;241m.\u001b[39mstyle\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     53\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     54\u001b[0m )\u001b[38;5;241m.\u001b[39mset_caption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPer-class precision/recall/f1 on the held-out test set\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Madi\\Documents\\season_25-26\\academic_25-26\\EE4211\\compvision_proj\\gesture-recog\\.venv\\lib\\site-packages\\pandas\\core\\indexing.py:1185\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1183\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[1;32m-> 1185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1187\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Madi\\Documents\\season_25-26\\academic_25-26\\EE4211\\compvision_proj\\gesture-recog\\.venv\\lib\\site-packages\\pandas\\core\\indexing.py:1376\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;66;03m# ugly hack for GH #836\u001b[39;00m\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multi_take_opportunity(tup):\n\u001b[1;32m-> 1376\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_multi_take\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple_same_dim(tup)\n",
      "File \u001b[1;32mc:\\Users\\Madi\\Documents\\season_25-26\\academic_25-26\\EE4211\\compvision_proj\\gesture-recog\\.venv\\lib\\site-packages\\pandas\\core\\indexing.py:1327\u001b[0m, in \u001b[0;36m_LocIndexer._multi_take\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;124;03mCreate the indexers for the passed tuple of keys, and\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;124;03mexecutes the take operation. This allows the take operation to be\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1324\u001b[0m \u001b[38;5;124;03mvalues: same type as the object being indexed\u001b[39;00m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;66;03m# GH 836\u001b[39;00m\n\u001b[1;32m-> 1327\u001b[0m d \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1328\u001b[0m     axis: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_listlike_indexer(key, axis)\n\u001b[0;32m   1329\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (key, axis) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(tup, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_AXIS_ORDERS)\n\u001b[0;32m   1330\u001b[0m }\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(d, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Madi\\Documents\\season_25-26\\academic_25-26\\EE4211\\compvision_proj\\gesture-recog\\.venv\\lib\\site-packages\\pandas\\core\\indexing.py:1328\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;124;03mCreate the indexers for the passed tuple of keys, and\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;124;03mexecutes the take operation. This allows the take operation to be\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1324\u001b[0m \u001b[38;5;124;03mvalues: same type as the object being indexed\u001b[39;00m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;66;03m# GH 836\u001b[39;00m\n\u001b[0;32m   1327\u001b[0m d \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m-> 1328\u001b[0m     axis: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1329\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (key, axis) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(tup, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_AXIS_ORDERS)\n\u001b[0;32m   1330\u001b[0m }\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(d, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Madi\\Documents\\season_25-26\\academic_25-26\\EE4211\\compvision_proj\\gesture-recog\\.venv\\lib\\site-packages\\pandas\\core\\indexing.py:1559\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1556\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[0;32m   1557\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[1;32m-> 1559\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1561\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[1;32mc:\\Users\\Madi\\Documents\\season_25-26\\academic_25-26\\EE4211\\compvision_proj\\gesture-recog\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6199\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6196\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6197\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6199\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6201\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6203\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Madi\\Documents\\season_25-26\\academic_25-26\\EE4211\\compvision_proj\\gesture-recog\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6248\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[0;32m   6247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[1;32m-> 6248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6250\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['Stop', 'Fist', 'Like', 'Thumbs Down'], dtype='object')] are in the [index]\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('gesture_data.csv')\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df['label'].values\n",
    "\n",
    "# Train/test split (stratified)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# SVM pipeline\n",
    "clf = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SVC(kernel='rbf', C=10, gamma='scale', probability=True)\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "gesture_labels = [\"Stop\", \"Fist\", \"Like\", \"Thumbs Down\"]\n",
    "\n",
    "# Build per-class metrics table\n",
    "report_dict = classification_report(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    target_names=gesture_labels,\n",
    "    output_dict=True,\n",
    "    zero_division=0,\n",
    ")\n",
    "report_df = pd.DataFrame(report_dict).T  # gestures become index\n",
    "per_class_df = (\n",
    "    report_df\n",
    "    .loc[gesture_labels, [\"precision\", \"recall\", \"f1-score\", \"support\"]]\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"Gesture\", \"f1-score\": \"f1\"})\n",
    ")\n",
    "per_class_df['support'] = per_class_df['support'].astype(int)\n",
    "styled_metrics = per_class_df.style.format(\n",
    "    {\"precision\": \"{:.3f}\", \"recall\": \"{:.3f}\", \"f1\": \"{:.3f}\"}\n",
    ").set_caption(\"Per-class precision/recall/f1 on the held-out test set\")\n",
    "display(styled_metrics)\n",
    "\n",
    "# Persist metrics for the report\n",
    "metrics_dir = Path('metrics')\n",
    "metrics_dir.mkdir(exist_ok=True)\n",
    "per_class_df.to_csv(metrics_dir / 'per_class_metrics.csv', index=False)\n",
    "per_class_df.to_latex(metrics_dir / 'per_class_metrics.tex', index=False, float_format='%.3f')\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Blues',\n",
    "    xticklabels=gesture_labels,\n",
    "    yticklabels=gesture_labels,\n",
    ")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix – Static Hand Gesture Classifier')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save model\n",
    "joblib.dump(clf, 'gesture_classifier.pkl')\n",
    "print(\"Saved model to gesture_classifier.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-Time Inference & System Control\n",
    "\n",
    "This module implements a hybrid gesture recognition system combining **static pose classification** with **zone-based navigation** for media control.\n",
    "\n",
    "### System Architecture\n",
    "\n",
    "**Static Gesture Recognition:**\n",
    "- SVM classifier with RBF kernel processes 63D landmark features\n",
    "- Confidence threshold: **p ≥ 0.88**\n",
    "- Stability requirement: **3 consecutive frames**\n",
    "- Debounce interval: **1.1 seconds**\n",
    "\n",
    "**Zone-Based Navigation:**\n",
    "- Screen partitioned into three horizontal zones: LEFT (0–25%), CENTER (25–75%), RIGHT (75–100%)\n",
    "- Transitions from CENTER → edge zones trigger media navigation\n",
    "- Cooldown: **1.5 seconds** between swipe actions\n",
    "\n",
    "### Gesture Mapping\n",
    "\n",
    "| Mode | Gesture | System Action |\n",
    "|------|---------|---------------|\n",
    "| Static (CENTER) | Stop (open palm) | Media play/pause toggle |\n",
    "| Static (CENTER) | Fist | Audio mute toggle |\n",
    "| Static (CENTER) | Like (thumbs up) | Volume +10% |\n",
    "| Static (CENTER) | Thumbs Down | Volume −10% |\n",
    "| Navigation | CENTER → LEFT zone | Previous track |\n",
    "| Navigation | CENTER → RIGHT zone | Next track |\n",
    "\n",
    "### Execution Requirements\n",
    "\n",
    "- **Platform:** Native Windows (WSL not supported due to `pycaw` dependency)\n",
    "- **Model:** `gesture_classifier.pkl` from training phase\n",
    "- **Hardware:** Functional webcam, audio output device\n",
    "- **Permissions:** Camera access, system audio control\n",
    "\n",
    "### Usage Notes\n",
    "\n",
    "- Static gestures only trigger in CENTER zone\n",
    "- Use two-hand strategy: one for navigation, one for static controls\n",
    "- Visual feedback: zone indicators, confidence meters, action confirmations\n",
    "- Press `q` to terminate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume control initialized successfully.\n",
      "Confidence threshold: 0.88\n",
      "\n",
      "=== ZONE-BASED NAVIGATION (Enhanced) ===\n",
      "Screen zones: LEFT (0-25%) | CENTER (25-75%) | RIGHT (75-100%)\n",
      "\n",
      "NAVIGATION:\n",
      "  - Keep hand in CENTER zone for static gestures\n",
      "  - Move to LEFT edge → Previous track\n",
      "  - Move to RIGHT edge → Next track\n",
      "  - Return to CENTER before next swipe\n",
      "\n",
      "STATIC GESTURES (use in CENTER):\n",
      "  Stop (palm) = Play/Pause\n",
      "  Fist = Mute\n",
      "  Like (thumbs up) = Vol+\n",
      "  Thumbs Down = Vol-\n",
      "\n",
      "TIPS FOR ROBUST CONTROL:\n",
      "  1. Use ONE hand for swipes, OTHER hand for static gestures\n",
      "  2. When swiping, make a FIST to avoid triggering static gestures\n",
      "  3. Hold static gestures steady for ~1 second in CENTER zone\n",
      "  4. Keep hand at chest height, well-lit, and clearly visible\n",
      "=======================================\n",
      "\n",
      "Starting gesture control. Press 'q' to quit.\n",
      "Starting gesture control. Press 'q' to quit.\n",
      ">>> RIGHT ZONE → Next Track\n",
      ">>> RIGHT ZONE → Next Track\n",
      ">>> RIGHT ZONE → Next Track\n",
      ">>> RIGHT ZONE → Next Track\n",
      "✓ Stop → Play/Pause\n",
      "✓ Stop → Play/Pause\n",
      "✓ Stop → Play/Pause\n",
      "✓ Stop → Play/Pause\n",
      "✓ Stop → Play/Pause\n",
      "✓ Stop → Play/Pause\n",
      "✓ Stop → Play/Pause\n",
      "✓ Stop → Play/Pause\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pyautogui\n",
    "from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume\n",
    "from comtypes import CLSCTX_ALL\n",
    "from ctypes import cast, POINTER\n",
    "import time\n",
    "\n",
    "# Gesture names must match training order\n",
    "gesture_names = [\"Stop\", \"Fist\", \"Like\", \"Thumbs Down\"]\n",
    "\n",
    "# Load trained classifier\n",
    "clf = joblib.load('gesture_classifier.pkl')\n",
    "\n",
    "# Setup MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.7)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Setup system volume control (pycaw)\n",
    "try:\n",
    "    devices = AudioUtilities.GetSpeakers()\n",
    "    interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "    volume = cast(interface, POINTER(IAudioEndpointVolume))\n",
    "    print(\"Volume control initialized successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Warning: Could not initialize volume control: {e}\")\n",
    "    volume = None\n",
    "\n",
    "# Static gesture state - INCREASED THRESHOLDS\n",
    "confidence_threshold = 0.88  # Higher confidence required\n",
    "cooldown_seconds = 1.1  # Longer cooldown\n",
    "last_gesture = -1\n",
    "last_trigger_time = 0.0\n",
    "stable_count = 0\n",
    "stable_threshold = 3  # Need 3 consecutive frames\n",
    "\n",
    "# ZONE-BASED SWIPE - WIDER CENTER ZONE\n",
    "swipe_state = \"CENTER\"\n",
    "swipe_last_action = 0.0\n",
    "swipe_cooldown = 1.5  # Longer cooldown for swipes\n",
    "zone_left = 0.25  # Wider center: only left 25% is LEFT zone\n",
    "zone_right = 0.75  # Only right 25% is RIGHT zone (center is 50% wide)\n",
    "\n",
    "print(f\"Confidence threshold: {confidence_threshold}\")\n",
    "print(\"\\n=== ZONE-BASED NAVIGATION (Enhanced) ===\")\n",
    "print(\"Screen zones: LEFT (0-25%) | CENTER (25-75%) | RIGHT (75-100%)\")\n",
    "print(\"\")\n",
    "print(\"NAVIGATION:\")\n",
    "print(\"  - Keep hand in CENTER zone for static gestures\")\n",
    "print(\"  - Move to LEFT edge → Previous track\")\n",
    "print(\"  - Move to RIGHT edge → Next track\")\n",
    "print(\"  - Return to CENTER before next swipe\")\n",
    "print(\"\")\n",
    "print(\"STATIC GESTURES (use in CENTER):\")\n",
    "print(\"  Stop (palm) = Play/Pause\")\n",
    "print(\"  Fist = Mute\")\n",
    "print(\"  Like (thumbs up) = Vol+\")\n",
    "print(\"  Thumbs Down = Vol-\")\n",
    "print(\"\")\n",
    "print(\"TIPS FOR ROBUST CONTROL:\")\n",
    "print(\"  1. Use ONE hand for swipes, OTHER hand for static gestures\")\n",
    "print(\"  2. When swiping, make a FIST to avoid triggering static gestures\")\n",
    "print(\"  3. Hold static gestures steady for ~1 second in CENTER zone\")\n",
    "print(\"  4. Keep hand at chest height, well-lit, and clearly visible\")\n",
    "print(\"=======================================\\n\")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "window_name = 'Gesture Control – Press q to quit'\n",
    "cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(window_name, 1600, 900)\n",
    "\n",
    "print(\"Starting gesture control. Press 'q' to quit.\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    h, w, _ = frame.shape\n",
    "    \n",
    "    # Draw zone dividers with WIDER center\n",
    "    left_x = int(w * zone_left)\n",
    "    right_x = int(w * zone_right)\n",
    "    cv2.line(frame, (left_x, 0), (left_x, h), (150, 150, 150), 3)\n",
    "    cv2.line(frame, (right_x, 0), (right_x, h), (150, 150, 150), 3)\n",
    "    \n",
    "    # Zone labels\n",
    "    cv2.putText(frame, \"LEFT\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (150, 150, 150), 2)\n",
    "    cv2.putText(frame, \"CENTER (Static Gestures)\", (left_x + 80, 50), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (150, 150, 150), 2)\n",
    "    cv2.putText(frame, \"RIGHT\", (right_x + 50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (150, 150, 150), 2)\n",
    "    \n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(rgb_frame)\n",
    "    now = time.time()\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            wrist = hand_landmarks.landmark[0]\n",
    "            wrist_x = wrist.x\n",
    "            \n",
    "            # --- ZONE-BASED SWIPE ---\n",
    "            new_state = swipe_state\n",
    "            if wrist_x < zone_left:\n",
    "                new_state = \"LEFT\"\n",
    "            elif wrist_x > zone_right:\n",
    "                new_state = \"RIGHT\"\n",
    "            else:\n",
    "                new_state = \"CENTER\"\n",
    "            \n",
    "            # Trigger on zone transition FROM CENTER\n",
    "            if now - swipe_last_action > swipe_cooldown:\n",
    "                if swipe_state == \"CENTER\" and new_state == \"LEFT\":\n",
    "                    pyautogui.press('prevtrack')\n",
    "                    print(\"<<< LEFT ZONE → Previous Track\")\n",
    "                    cv2.putText(frame, \"<<< PREVIOUS\", (50, 200), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 2.5, (0, 255, 255), 5)\n",
    "                    swipe_last_action = now\n",
    "                    stable_count = 0  # Reset static gesture counter\n",
    "                elif swipe_state == \"CENTER\" and new_state == \"RIGHT\":\n",
    "                    pyautogui.press('nexttrack')\n",
    "                    print(\">>> RIGHT ZONE → Next Track\")\n",
    "                    cv2.putText(frame, \"NEXT >>>\", (w - 450, 200), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 2.5, (0, 255, 255), 5)\n",
    "                    swipe_last_action = now\n",
    "                    stable_count = 0  # Reset static gesture counter\n",
    "            \n",
    "            swipe_state = new_state\n",
    "            \n",
    "            # Show current zone with emphasis\n",
    "            zone_text = f\"Zone: {swipe_state}\"\n",
    "            if swipe_state == \"CENTER\":\n",
    "                zone_color = (0, 255, 0)  # Green for center\n",
    "                zone_bg_color = (0, 80, 0)\n",
    "            else:\n",
    "                zone_color = (255, 150, 0)  # Orange for edges\n",
    "                zone_bg_color = (80, 50, 0)\n",
    "            \n",
    "            # Background for zone text\n",
    "            cv2.rectangle(frame, (40, 80), (280, 130), zone_bg_color, -1)\n",
    "            cv2.putText(frame, zone_text, (50, 120), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1.2, zone_color, 3)\n",
    "\n",
    "            # --- STATIC GESTURE RECOGNITION (ONLY IN CENTER ZONE) ---\n",
    "            if swipe_state != \"CENTER\":\n",
    "                stable_count = 0\n",
    "                cv2.putText(frame, \"Static gestures disabled in edge zones\", (50, 680), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 165, 255), 2)\n",
    "                continue\n",
    "            \n",
    "            # Check if recently swiped\n",
    "            if now - swipe_last_action < 0.6:\n",
    "                stable_count = 0\n",
    "                continue\n",
    "            \n",
    "            xs = [lm.x for lm in hand_landmarks.landmark]\n",
    "            ys = [lm.y for lm in hand_landmarks.landmark]\n",
    "            bbox_area = (max(xs) - min(xs)) * (max(ys) - min(ys))\n",
    "            \n",
    "            if bbox_area < 0.008:\n",
    "                stable_count = 0\n",
    "                continue\n",
    "\n",
    "            landmarks = []\n",
    "            for lm in hand_landmarks.landmark:\n",
    "                landmarks.extend([lm.x, lm.y, lm.z])\n",
    "            landmarks = np.array([landmarks])\n",
    "\n",
    "            probs = clf.predict_proba(landmarks)[0]\n",
    "            prediction = int(np.argmax(probs))\n",
    "            confidence = float(np.max(probs))\n",
    "\n",
    "            gesture_name = gesture_names[prediction] if prediction < len(gesture_names) else f\"Class {prediction}\"\n",
    "            \n",
    "            # Stability tracking\n",
    "            if confidence >= confidence_threshold:\n",
    "                if prediction == last_gesture or last_gesture == -1:\n",
    "                    stable_count += 1\n",
    "                else:\n",
    "                    stable_count = 1\n",
    "                    last_gesture = prediction\n",
    "                    \n",
    "                ready_to_trigger = (stable_count >= stable_threshold and \n",
    "                                   now - last_trigger_time >= cooldown_seconds)\n",
    "                \n",
    "                if ready_to_trigger:\n",
    "                    color = (0, 255, 0)  # GREEN - ready\n",
    "                    status = \"[READY]\"\n",
    "                else:\n",
    "                    color = (0, 165, 255)  # ORANGE - building stability\n",
    "                    status = f\"[{stable_count}/{stable_threshold}]\"\n",
    "            else:\n",
    "                color = (0, 0, 255)  # RED - low confidence\n",
    "                status = \"[LOW CONF]\"\n",
    "                stable_count = 0\n",
    "\n",
    "            # Display prediction with stability counter\n",
    "            txt_x = max(10, min(w - 300, int(wrist_x * w)))\n",
    "            txt_y = max(80, min(h - 50, int(wrist.y * h) - 40))\n",
    "            label = f\"{gesture_name} {status} ({confidence:.2f})\"\n",
    "            cv2.putText(frame, label, (txt_x, txt_y), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 3, cv2.LINE_AA)\n",
    "\n",
    "            # Execute action only when fully stable\n",
    "            if confidence >= confidence_threshold and stable_count >= stable_threshold:\n",
    "                if now - last_trigger_time >= cooldown_seconds:\n",
    "                    if prediction == 0:  # Stop\n",
    "                        pyautogui.press('playpause')\n",
    "                        print(f\"✓ {gesture_name} → Play/Pause\")\n",
    "                        cv2.putText(frame, \"PLAY/PAUSE\", (w//2 - 150, h//2), \n",
    "                                   cv2.FONT_HERSHEY_SIMPLEX, 2.0, (0, 255, 0), 4)\n",
    "                    elif prediction == 1 and volume:  # Fist\n",
    "                        muted = volume.GetMute()\n",
    "                        volume.SetMute(not muted, None)\n",
    "                        print(f\"✓ {gesture_name} → Mute Toggle\")\n",
    "                        cv2.putText(frame, \"MUTE\", (w//2 - 80, h//2), \n",
    "                                   cv2.FONT_HERSHEY_SIMPLEX, 2.0, (255, 0, 0), 4)\n",
    "                    elif prediction == 2 and volume:  # Like\n",
    "                        current = volume.GetMasterVolumeLevelScalar()\n",
    "                        volume.SetMasterVolumeLevelScalar(min(1.0, current + 0.1), None)\n",
    "                        print(f\"✓ {gesture_name} → Volume UP\")\n",
    "                        cv2.putText(frame, \"VOL +\", (w//2 - 80, h//2), \n",
    "                                   cv2.FONT_HERSHEY_SIMPLEX, 2.0, (0, 255, 0), 4)\n",
    "                    elif prediction == 3 and volume:  # Thumbs Down\n",
    "                        current = volume.GetMasterVolumeLevelScalar()\n",
    "                        volume.SetMasterVolumeLevelScalar(max(0.0, current - 0.1), None)\n",
    "                        print(f\"✓ {gesture_name} → Volume DOWN\")\n",
    "                        cv2.putText(frame, \"VOL -\", (w//2 - 80, h//2), \n",
    "                                   cv2.FONT_HERSHEY_SIMPLEX, 2.0, (255, 165, 0), 4)\n",
    "                    \n",
    "                    last_gesture = prediction\n",
    "                    last_trigger_time = now\n",
    "                    stable_count = 0\n",
    "\n",
    "    else:\n",
    "        stable_count = 0\n",
    "        swipe_state = \"CENTER\"\n",
    "\n",
    "    cv2.imshow(window_name, frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMwgDCLNKwylnUuZQXMjVc5",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (.venv gesture-recog)",
   "language": "python",
   "name": "gesture-recog"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
